{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import cv2\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess_transforms():\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    return preprocess\n",
    "\n",
    "def image_common_transforms(mean=(0.5043, 0.4968, 0.4870), std=(0.1937, 0.1901, 0.1887)):\n",
    "    preprocess = image_preprocess_transforms()\n",
    "    \n",
    "    common_transforms = transforms.Compose([\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return common_transforms\n",
    "\n",
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 21  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)\n",
    "        \n",
    "\n",
    "    \n",
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir='', model_file_name='CIPP_classifier_6_classes_v5.pt'):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagemNaoEnviada(Exception):  pass\n",
    "\n",
    "class CIPP(Dataset):\n",
    "\n",
    "    \n",
    "    def __init__(self, data_root, num_cipp, image_shape=None, transform=None):\n",
    "        \n",
    "        \n",
    "        # set image_resize attribute\n",
    "        if image_shape is not None:\n",
    "            if isinstance(image_shape, int):\n",
    "                self.image_shape = (image_shape, image_shape)\n",
    "            \n",
    "            elif isinstance(image_shape, tuple) or isinstance(image_shape, list):\n",
    "                assert len(image_shape) == 1 or len(image_shape) == 2, 'Invalid image_shape tuple size'\n",
    "                if len(image_shape) == 1:\n",
    "                    self.image_shape = (image_shape[0], image_shape[0])\n",
    "                else:\n",
    "                    self.image_shape = image_shape\n",
    "            else:\n",
    "                raise NotImplementedError \n",
    "                \n",
    "        else:\n",
    "            self.image_shape = image_shape\n",
    "            \n",
    "        # set transform attribute\n",
    "        self.transform = transform\n",
    "                \n",
    "        \n",
    "        # initialize the data dictionary\n",
    "        self.data_dict = {\n",
    "            'image_path': [],\n",
    "            'n_cipp': []\n",
    "        }\n",
    "        \n",
    "           \n",
    "\n",
    "        class_path = os.path.join(data_root, num_cipp)\n",
    "\n",
    "        for img in os.listdir(class_path):\n",
    "            if img.lower().endswith(\".jpg\") or img.endswith(\".png\"):\n",
    "                img_path = os.path.join(class_path, img)\n",
    "                self.data_dict['image_path'].append(img_path)\n",
    "                self.data_dict['n_cipp'].append(str(num_cipp))\n",
    "        if (len(self.data_dict['image_path'])==0):\n",
    "            raise ImagemNaoEnviada()\n",
    "            \n",
    "                    \n",
    "    def __len__(self):\n",
    "    \n",
    "        \"\"\"\n",
    "        return length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data_dict['image_path'])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For given index, return images with resize and preprocessing.\n",
    "        \"\"\"\n",
    "        image = Image.open(self.data_dict['image_path'][idx]).convert(\"RGB\")\n",
    "\n",
    "        im_hash = hashlib.sha1(image.tobytes())\n",
    "        im_hash=im_hash.hexdigest()\n",
    "        if self.image_shape is not None:\n",
    "            image = F.resize(image, self.image_shape)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    " \n",
    "        n_cipp = self.data_dict['n_cipp'][idx]\n",
    "        image_path=self.data_dict['image_path'][idx]\n",
    "        return image, n_cipp, image_path,im_hash   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, device, batch_input):\n",
    "    \n",
    "    # send model to cpu/cuda according to your system configuration\n",
    "    model.to(device)\n",
    "    \n",
    "    # it is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "\n",
    "    #data = batch_input.to(device)\n",
    "\n",
    "    output = model(batch_input)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "\n",
    "    # get the max probability\n",
    "    pred_prob = prob.data.max(dim=1)[0]\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_resnet50(transfer_learning=True, num_class=6):\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    \n",
    "    if transfer_learning:\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    last_layer_in = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(last_layer_in, num_class)\n",
    "    \n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = pretrained_resnet50()\n",
    "model = load_model(model)\n",
    "\n",
    "model_copy = pretrained_resnet50()\n",
    "model_copy = load_model(model_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "\n",
    "idt=0\n",
    "\n",
    "inicio = time.time()\n",
    "device='cpu'\n",
    "\n",
    "transform = image_common_transforms()\n",
    "classes=[\"CIPP_Frente\",\"CIPP_Verso\",\"Manometro\",\"Não Tanque\",\"Placas\",\"Tanque\"]\n",
    "\n",
    "for cipp in os.listdir(home):\n",
    "    dataset =  CIPP(home, num_cipp=cipp,transform=transform)\n",
    "\n",
    "    data_len = dataset.__len__()\n",
    "\n",
    "    imgs = []\n",
    "    n_cipps = []\n",
    "    im_paths = []\n",
    "    im_hashes=[]\n",
    "    for i in range(data_len):\n",
    "        img, num_cipp, image_path, im_hash = dataset.__getitem__(i)\n",
    "        imgs.append(img)\n",
    "        n_cipps.append(num_cipp) \n",
    "        im_paths.append(image_path.replace(\"'\",\"''\"))\n",
    "        im_hashes.append(im_hash)\n",
    "\n",
    "    imgs = torch.stack(imgs)\n",
    "\n",
    "    cls, prob = prediction(model, device=\"cpu\", batch_input=imgs)\n",
    "\n",
    "    sql=''   \n",
    "    image_path=''\n",
    "    TB_INSPECAO_CIPP_FOTOS_CLONAGEM=[]\n",
    "    TB_FOTO_AVALIACAO_CLONAGEM=[]\n",
    "    for i in range(data_len):\n",
    "\n",
    "        image_path=im_paths[i]\n",
    "        TB_INSPECAO_CIPP_FOTOS_CLONAGEM.append((cipp, 'R', im_paths[i],im_hashes[i]))#,previsao,precisao)\n",
    "        \n",
    "\n",
    "\n",
    "        previsao=classes[cls[i]]\n",
    "        precisao=prob[i]\n",
    "\n",
    "\n",
    "        id_inserido = 0\n",
    "\n",
    "        TB_FOTO_AVALIACAO_CLONAGEM.append((id_inserido,1 ,previsao,precisao))\n",
    "\n",
    "       \n",
    "\n",
    "    \n",
    "fim = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagem imagem_adulterada1.jpg com HASH c1197915d39aa081cbd1cfa9ce95b9efa2f4b5b5\n",
      "Imagem imagem_base_sem adulteracao.jpg com HASH e2ca2329e526904875f37a4a38f730bdfbfc9be3\n"
     ]
    }
   ],
   "source": [
    "%run assinatura_foto.py\n",
    "#na primeira execução baixou resnet50 da web\n",
    "fotos=[]\n",
    "for item in TB_INSPECAO_CIPP_FOTOS_CLONAGEM:\n",
    "    print('Imagem %s com HASH %s'%(item[2].split('\\\\')[8], item[3]))\n",
    "    fotos.append(item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distância entre as imagens: 44.255966\n"
     ]
    }
   ],
   "source": [
    "fot=[]\n",
    "for foto in fotos:\n",
    "    fot.append((foto,carregaTensor_to_numpy(foto,model)))\n",
    "matriz=[]  \n",
    "#print(fot)\n",
    "X1=fot[0][1]\n",
    "Y=fot[1][1]\n",
    "dist = np.linalg.norm(X1-Y)\n",
    "print('Distância entre as imagens: %f'%(dist))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
